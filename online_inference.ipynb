{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-07T12:57:44.986899Z",
     "iopub.status.busy": "2021-01-07T12:57:44.986164Z",
     "iopub.status.idle": "2021-01-07T12:57:47.658803Z",
     "shell.execute_reply": "2021-01-07T12:57:47.658096Z"
    },
    "papermill": {
     "duration": 2.695227,
     "end_time": "2021-01-07T12:57:47.659000",
     "exception": false,
     "start_time": "2021-01-07T12:57:44.963773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "from collections import defaultdict, OrderedDict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bitarray import bitarray\n",
    "import lightgbm as lgb\n",
    "\n",
    "import psutil\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012127,
     "end_time": "2021-01-07T12:57:47.684001",
     "exception": false,
     "start_time": "2021-01-07T12:57:47.671874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM with uc cache 0.794 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:57:47.722068Z",
     "iopub.status.busy": "2021-01-07T12:57:47.721363Z",
     "iopub.status.idle": "2021-01-07T12:57:47.724391Z",
     "shell.execute_reply": "2021-01-07T12:57:47.723769Z"
    },
    "papermill": {
     "duration": 0.027459,
     "end_time": "2021-01-07T12:57:47.724519",
     "exception": false,
     "start_time": "2021-01-07T12:57:47.697060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LRUCache(OrderedDict):\n",
    "\n",
    "    def __init__(self, capacity=8000000):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "     \n",
    "\n",
    "    def get(self,key):\n",
    "        if key in self.cache:\n",
    "            value = self.cache.pop(key)\n",
    "            self.cache[key] = value\n",
    "        else:\n",
    "            value = -1\n",
    "         \n",
    "        return value\n",
    "     \n",
    "\n",
    "    def set(self,key,value):\n",
    "        if key in self.cache:\n",
    "            value = self.cache.pop(key)\n",
    "            self.cache[key] = value\n",
    "        else:\n",
    "            if len(self.cache) == self.capacity:\n",
    "                self.cache.popitem(last = False)\n",
    "                self.cache[key] = value\n",
    "            else:\n",
    "                self.cache[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:57:47.857523Z",
     "iopub.status.busy": "2021-01-07T12:57:47.841985Z",
     "iopub.status.idle": "2021-01-07T12:59:19.227733Z",
     "shell.execute_reply": "2021-01-07T12:59:19.227053Z"
    },
    "papermill": {
     "duration": 91.490371,
     "end_time": "2021-01-07T12:59:19.227871",
     "exception": false,
     "start_time": "2021-01-07T12:57:47.737500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading prepared data\n",
    "\n",
    "with open('../input/riiiduploadcache800w/uc_cache.pickle', 'rb') as handle:\n",
    "    lru_cache = pickle.load(handle)\n",
    "\n",
    "with open('../input/riiiduploadcache800w/u_question_seen_dict.pickle', 'rb') as handle:\n",
    "    u_question_seen_dict = pickle.load(handle)\n",
    "\n",
    "with open('../input/riiiduploadcache800w/u_answered_correctly_count_dict.pickle', 'rb') as handle:\n",
    "    u_answered_correctly_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_answered_count_dict.pickle', 'rb') as handle:\n",
    "    u_answered_count_dict = pickle.load(handle)\n",
    "\n",
    "with open('../input/riiiduploadcache800w/u_question_part_correctly_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_part_correctly_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_part_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_part_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_tag1_correctly_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_tag1_correctly_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_tag1_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_tag1_count_dict = pickle.load(handle)\n",
    "\n",
    "with open('../input/riiiduploadcache800w/u_prior_question_correctly_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior_question_correctly_timestamp_dict = pickle.load(handle) \n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior2_question_correctly_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior2_question_correctly_timestamp_dict = pickle.load(handle)  \n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior3_question_correctly_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior3_question_correctly_timestamp_dict = pickle.load(handle)  \n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior_question_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior_question_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior2_question_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior2_question_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior3_question_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior3_question_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior4_question_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior4_question_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior_lecture_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior_lecture_timestamp_dict = pickle.load(handle)\n",
    "\n",
    "with open('../input/riiiduploadcache800w/u_prior2_lecture_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_prior2_lecture_timestamp_dict = pickle.load(handle)    \n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_task_container_id_dict.pickle', 'rb') as handle:\n",
    "    u_task_container_id_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior_question_explanation_count_dict.pickle', 'rb') as handle:\n",
    "    u_prior_question_explanation_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_prior_question_explanation_correctly_count_dict.pickle', 'rb') as handle:\n",
    "    u_prior_question_explanation_correctly_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_listening_correctly_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_listening_correctly_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_reading_correctly_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_reading_correctly_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_listening_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_listening_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_reading_count_dict.pickle', 'rb') as handle:\n",
    "    u_question_reading_count_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_incorrect_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_question_incorrect_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_incorrect_timestamp2_dict.pickle', 'rb') as handle:\n",
    "    u_question_incorrect_timestamp2_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_incorrect_timestamp3_dict.pickle', 'rb') as handle:\n",
    "    u_question_incorrect_timestamp3_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_part_correct_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_question_part_correct_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "with open('../input/riiiduploadcache800w/u_question_part_incorrect_timestamp_dict.pickle', 'rb') as handle:\n",
    "    u_question_part_incorrect_timestamp_dict = pickle.load(handle)\n",
    "    \n",
    "questions_df = pd.read_pickle('../input/riiiduploadcache800w/questions_df.pickle')\n",
    "content_df = pd.read_pickle('../input/riiiduploadcache800w/content_df.pickle')\n",
    "\n",
    "# loading trained model\n",
    "\n",
    "model = lgb.Booster(model_file='../input/riiiduploadcache800w/lgb_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:19.308109Z",
     "iopub.status.busy": "2021-01-07T12:59:19.270057Z",
     "iopub.status.idle": "2021-01-07T12:59:19.340305Z",
     "shell.execute_reply": "2021-01-07T12:59:19.339468Z"
    },
    "papermill": {
     "duration": 0.098564,
     "end_time": "2021-01-07T12:59:19.340448",
     "exception": false,
     "start_time": "2021-01-07T12:59:19.241884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_user_feats_without_update(df, \n",
    "                                  u_answered_correctly_count_dict, \n",
    "                                  u_answered_count_dict, \n",
    "                                  u_question_part_correctly_count_dict,\n",
    "                                  u_question_part_count_dict,\n",
    "                                  u_question_tag1_correctly_count_dict,\n",
    "                                  u_question_tag1_count_dict,\n",
    "                                  u_prior_question_correctly_timestamp_dict,\n",
    "                                  u_prior2_question_correctly_timestamp_dict,\n",
    "                                  u_prior3_question_correctly_timestamp_dict,\n",
    "                                  u_prior_question_timestamp_dict,\n",
    "                                  u_prior2_question_timestamp_dict,\n",
    "                                  u_prior3_question_timestamp_dict,\n",
    "                                  u_prior4_question_timestamp_dict,\n",
    "                                  u_prior_lecture_timestamp_dict,\n",
    "                                  u_prior2_lecture_timestamp_dict,\n",
    "                                  u_task_container_id_dict,\n",
    "                                  u_prior_question_explanation_count_dict,\n",
    "                                  u_prior_question_explanation_correctly_count_dict,\n",
    "                                  u_question_listening_correctly_count_dict,\n",
    "                                  u_question_reading_correctly_count_dict,\n",
    "                                  u_question_listening_count_dict,\n",
    "                                  u_question_reading_count_dict,\n",
    "                                  u_question_incorrect_timestamp_dict,\n",
    "                                  u_question_incorrect_timestamp2_dict,\n",
    "                                  u_question_incorrect_timestamp3_dict,\n",
    "                                  u_question_seen_dict,\n",
    "                                  u_question_part_correct_timestamp_dict,\n",
    "                                  u_question_part_incorrect_timestamp_dict,\n",
    "                                 ):\n",
    "    \n",
    "    uacc = np.zeros(len(df), dtype=np.int32)\n",
    "    uac = np.zeros(len(df), dtype=np.int32)\n",
    "    uqpcc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqpc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqt1cc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqt1c = np.zeros(len(df), dtype=np.int32)\n",
    "    upqct = np.zeros(len(df), dtype=np.int32)\n",
    "    up2qct = np.zeros(len(df), dtype=np.int32)\n",
    "    up3qct = np.zeros(len(df), dtype=np.int32)\n",
    "    upqt = np.zeros(len(df), dtype=np.int32)\n",
    "    up2qt = np.zeros(len(df), dtype=np.int32)\n",
    "    up3qt = np.zeros(len(df), dtype=np.int32)\n",
    "    up4qt = np.zeros(len(df), dtype=np.int32)\n",
    "    uplt = np.zeros(len(df), dtype=np.int32)\n",
    "    up2lt = np.zeros(len(df), dtype=np.int32)\n",
    "    utci = np.zeros(len(df), dtype=np.int32)\n",
    "    upqec = np.zeros(len(df), dtype=np.int32)\n",
    "    upqecc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqlcc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqrcc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqlc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqrc = np.zeros(len(df), dtype=np.int32)\n",
    "    uqict = np.zeros(len(df), dtype=np.int32)\n",
    "    uqict2 = np.zeros(len(df), dtype=np.int32)\n",
    "    uqict3 = np.zeros(len(df), dtype=np.int32)\n",
    "    uqs = np.zeros(len(df), dtype=np.int32)\n",
    "    uqn = np.zeros(len(df), dtype=np.int32)\n",
    "    uqpct = np.zeros(len(df), dtype=np.int32)\n",
    "    uqpict = np.zeros(len(df), dtype=np.int32)\n",
    "    uct = np.zeros(len(df), dtype=np.int32)\n",
    "    \n",
    "    for cnt, row in enumerate(df[['user_id',\n",
    "                                  'content_type_id', \n",
    "                                  'part',\n",
    "                                  'tag1',\n",
    "                                  'timestamp',\n",
    "                                  'task_container_id',\n",
    "                                  'prior_question_had_explanation',\n",
    "                                  'LorR',\n",
    "                                  'content_id']].values):\n",
    "        user_id = row[0]\n",
    "        content_type = row[1]\n",
    "        question_part = row[2]\n",
    "        question_tag1 = row[3]\n",
    "        timestamp = row[4]\n",
    "        task_container_id = row[5]\n",
    "        prior_question_had_explanation = row[6]\n",
    "        LorR = row[7]\n",
    "        content_id = row[8]\n",
    "        \n",
    "        uid_part = str(user_id) + '_' + str(question_part)\n",
    "        uid_tag1 = str(user_id) + '_' + str(question_tag1)\n",
    "        uid_cid = int(user_id) + int(content_id)*10e10\n",
    "        \n",
    "        uct[cnt] = timestamp - lru_cache.get(uid_cid)\n",
    "        uacc[cnt] = u_answered_correctly_count_dict[user_id]\n",
    "        uac[cnt] = u_answered_count_dict[user_id]\n",
    "        uqpcc[cnt] = u_question_part_correctly_count_dict[uid_part]\n",
    "        uqpc[cnt] = u_question_part_count_dict[uid_part]\n",
    "        uqt1cc[cnt] = u_question_tag1_correctly_count_dict[uid_tag1]\n",
    "        uqt1c[cnt] = u_question_tag1_count_dict[uid_tag1]\n",
    "        upqct[cnt] = timestamp - u_prior_question_correctly_timestamp_dict[user_id]\n",
    "        up2qct[cnt] = timestamp - u_prior2_question_correctly_timestamp_dict[user_id]\n",
    "        up3qct[cnt] = timestamp - u_prior3_question_correctly_timestamp_dict[user_id]\n",
    "        upqt[cnt] = timestamp - u_prior_question_timestamp_dict[user_id]\n",
    "        up2qt[cnt] = timestamp - u_prior2_question_timestamp_dict[user_id]\n",
    "        up3qt[cnt] = timestamp - u_prior3_question_timestamp_dict[user_id]\n",
    "        up4qt[cnt] = timestamp - u_prior4_question_timestamp_dict[user_id]\n",
    "        uplt[cnt] = timestamp - u_prior_lecture_timestamp_dict[user_id]\n",
    "        up2lt[cnt] = timestamp - u_prior2_lecture_timestamp_dict[user_id]\n",
    "        utci[cnt] = task_container_id - u_task_container_id_dict[user_id]\n",
    "        upqec[cnt] = u_prior_question_explanation_count_dict[user_id]\n",
    "        upqecc[cnt] = u_prior_question_explanation_correctly_count_dict[user_id]\n",
    "        uqlcc[cnt] = u_question_listening_correctly_count_dict[user_id]\n",
    "        uqrcc[cnt] = u_question_reading_correctly_count_dict[user_id]\n",
    "        uqlc[cnt] = u_question_listening_count_dict[user_id]\n",
    "        uqrc[cnt] = u_question_reading_count_dict[user_id]\n",
    "        uqict[cnt] = timestamp - u_question_incorrect_timestamp_dict[user_id]\n",
    "        uqict2[cnt] = timestamp - u_question_incorrect_timestamp2_dict[user_id]\n",
    "        uqict3[cnt] = timestamp - u_question_incorrect_timestamp3_dict[user_id]\n",
    "        uqpct[cnt] = timestamp - u_question_part_correct_timestamp_dict[uid_part]\n",
    "        uqpict[cnt] = timestamp - u_question_part_incorrect_timestamp_dict[uid_part]\n",
    "        if content_type == 0:\n",
    "            if user_id not in u_question_seen_dict:\n",
    "                u_question_seen_dict[user_id] = bitarray('0'*14000, endian='little')\n",
    "            uqs[cnt] = u_question_seen_dict[user_id][content_id]\n",
    "            uqn[cnt] = u_question_seen_dict[user_id].count()\n",
    "        \n",
    "    user_feats_df = pd.DataFrame({'u_answered_correctly_count': uacc, \n",
    "                                  'u_answered_count': uac,\n",
    "                                  'u_question_part_correctly_count': uqpcc,\n",
    "                                  'u_question_part_count': uqpc,\n",
    "                                  'u_question_tag1_correctly_count': uqt1cc,\n",
    "                                  'u_question_tag1_count': uqt1c,\n",
    "                                  'u_prior_question_correctly_timestamp_diff': upqct,\n",
    "                                  'u_prior_question_correctly_timestamp_diff2': up2qct,\n",
    "                                  'u_prior_question_correctly_timestamp_diff3': up3qct,\n",
    "                                  'u_prior_question_timestamp_diff': upqt,\n",
    "                                  'u_prior_question_timestamp_diff2': up2qt,\n",
    "                                  'u_prior_question_timestamp_diff3': up3qt,\n",
    "                                  'u_prior_question_timestamp_diff4': up4qt,\n",
    "                                  'u_prior_lecture_timestamp_diff': uplt,\n",
    "                                  'u_prior2_lecture_timestamp_diff': up2lt,\n",
    "                                  'u_task_container_id_diff': utci,\n",
    "                                  'u_prior_question_explanation_count': upqec,\n",
    "                                  'u_prior_question_explanation_correctly_count': upqecc,\n",
    "                                  'u_question_listening_correctly_count': uqlcc,\n",
    "                                  'u_question_reading_correctly_count': uqrcc,\n",
    "                                  'u_question_listening_count': uqlc,\n",
    "                                  'u_question_reading_count': uqrc,\n",
    "                                  'u_question_incorrect_timestamp_diff': uqict,\n",
    "                                  'u_question_incorrect_timestamp_diff2': uqict2,\n",
    "                                  'u_question_incorrect_timestamp_diff3': uqict3,\n",
    "                                  'u_question_seen': uqs,\n",
    "                                  'u_question_nunique': uqn,\n",
    "                                  'u_question_part_correct_timestamp_diff': uqpct,\n",
    "                                  'u_question_part_incorrect_timestamp_diff': uqpict,\n",
    "                                  'uc_question_timestamp_diff': uct,\n",
    "                                  })\n",
    "    \n",
    "    user_feats_df['u_answered_correctly_avg'] = user_feats_df['u_answered_correctly_count'] / user_feats_df['u_answered_count']\n",
    "    user_feats_df['u_question_part_correctly_avg'] = user_feats_df['u_question_part_correctly_count'] / user_feats_df['u_question_part_count']\n",
    "    user_feats_df['u_question_tag1_correctly_avg'] = user_feats_df['u_question_tag1_correctly_count'] / user_feats_df['u_question_tag1_count']\n",
    "    user_feats_df['u_prior_question_timestamp_diff_2_1'] = user_feats_df['u_prior_question_timestamp_diff2'] - user_feats_df['u_prior_question_timestamp_diff']\n",
    "    user_feats_df['u_prior_question_timestamp_diff_3_2'] = user_feats_df['u_prior_question_timestamp_diff3'] - user_feats_df['u_prior_question_timestamp_diff2']\n",
    "    user_feats_df['u_prior_question_timestamp_diff_4_3'] = user_feats_df['u_prior_question_timestamp_diff4'] - user_feats_df['u_prior_question_timestamp_diff3']\n",
    "    \n",
    "    df = pd.concat([df, user_feats_df], axis=1)\n",
    "    df['u_question_timestamp_diff']  = df['u_prior_question_timestamp_diff_2_1'] - df['prior_question_elapsed_time']\n",
    "    df['u_question_timestamp_diff2']  = df['u_prior_question_timestamp_diff_3_2'] - df['prior_question_elapsed_time']\n",
    "    df['u_question_timestamp_diff3']  = df['u_prior_question_timestamp_diff_4_3'] - df['prior_question_elapsed_time']\n",
    "    df['u_listening_reading_ratio'] = df['u_question_listening_correctly_count'] / (1 + df['u_question_reading_correctly_count'])\n",
    "    df['u_listening_correctly_avg'] = df['u_question_listening_correctly_count'] / (1 + df['u_question_listening_count'])\n",
    "    df['u_reading_correctly_avg'] = df['u_question_reading_correctly_count'] / (1 + df['u_question_reading_count'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def update_user_feats(df, \n",
    "                      u_answered_correctly_count_dict,\n",
    "                      u_answered_count_dict, \n",
    "                      u_question_part_correctly_count_dict,\n",
    "                      u_question_part_count_dict,\n",
    "                      u_question_tag1_correctly_count_dict,\n",
    "                      u_question_tag1_count_dict,\n",
    "                      u_prior_question_correctly_timestamp_dict,\n",
    "                      u_prior2_question_correctly_timestamp_dict,\n",
    "                      u_prior3_question_correctly_timestamp_dict,\n",
    "                      u_prior_question_timestamp_dict,\n",
    "                      u_prior2_question_timestamp_dict,\n",
    "                      u_prior3_question_timestamp_dict,\n",
    "                      u_prior4_question_timestamp_dict,\n",
    "                      u_prior_lecture_timestamp_dict, \n",
    "                      u_prior2_lecture_timestamp_dict,\n",
    "                      u_task_container_id_dict,\n",
    "                      u_prior_question_explanation_count_dict,\n",
    "                      u_prior_question_explanation_correctly_count_dict,\n",
    "                      u_question_listening_correctly_count_dict, \n",
    "                      u_question_reading_correctly_count_dict,\n",
    "                      u_question_listening_count_dict,\n",
    "                      u_question_reading_count_dict,\n",
    "                      u_question_incorrect_timestamp_dict,\n",
    "                      u_question_incorrect_timestamp2_dict,\n",
    "                      u_question_incorrect_timestamp3_dict,\n",
    "                      u_question_seen_dict,\n",
    "                      u_question_part_correct_timestamp_dict,\n",
    "                      u_question_part_incorrect_timestamp_dict,\n",
    "                     ):\n",
    "    \n",
    "    for cnt, row in enumerate(df[['user_id',\n",
    "                                  'content_type_id',\n",
    "                                  'answered_correctly', \n",
    "                                  'part',\n",
    "                                  'tag1',\n",
    "                                  'timestamp',\n",
    "                                  'task_container_id',\n",
    "                                  'prior_question_had_explanation',\n",
    "                                  'LorR',\n",
    "                                  'content_id']].values):\n",
    "        user_id = row[0]\n",
    "        content_type = row[1]\n",
    "        answered_correctly = row[2]\n",
    "        question_part = row[3]\n",
    "        question_tag1 = row[4]\n",
    "        timestamp = row[5]\n",
    "        task_container_id = row[6]\n",
    "        prior_question_had_explanation = row[7]\n",
    "        LorR = row[8]\n",
    "        content_id = row[9]\n",
    "        \n",
    "        uid_part = str(user_id) + '_' + str(question_part)\n",
    "        uid_tag1 = str(user_id) + '_' + str(question_tag1)\n",
    "        uid_cid = int(user_id) + int(content_id)*10e10\n",
    "        \n",
    "        if content_type == 0:\n",
    "            \n",
    "            if answered_correctly == 1:\n",
    "                u_prior3_question_correctly_timestamp_dict[user_id] = u_prior2_question_correctly_timestamp_dict[user_id]\n",
    "                u_prior2_question_correctly_timestamp_dict[user_id] = u_prior_question_correctly_timestamp_dict[user_id]\n",
    "                u_prior_question_correctly_timestamp_dict[user_id] = timestamp\n",
    "                u_prior_question_explanation_correctly_count_dict[user_id] += 1\n",
    "                u_question_part_correct_timestamp_dict[uid_part] = timestamp\n",
    "                if LorR == 0:\n",
    "                    u_question_listening_correctly_count_dict[user_id] += 1\n",
    "                else:\n",
    "                    u_question_reading_correctly_count_dict[user_id] += 1\n",
    "            else:\n",
    "                u_question_incorrect_timestamp3_dict[user_id] = u_question_incorrect_timestamp2_dict[user_id]\n",
    "                u_question_incorrect_timestamp2_dict[user_id] = u_question_incorrect_timestamp_dict[user_id]\n",
    "                u_question_incorrect_timestamp_dict[user_id] = timestamp\n",
    "                u_question_part_incorrect_timestamp_dict[uid_part] = timestamp\n",
    "                \n",
    "            u_answered_correctly_count_dict[user_id] += answered_correctly\n",
    "            u_answered_count_dict[user_id] += 1\n",
    "            u_question_part_correctly_count_dict[uid_part] += answered_correctly\n",
    "            u_question_part_count_dict[uid_part] += 1\n",
    "            u_question_tag1_correctly_count_dict[uid_tag1] += answered_correctly\n",
    "            u_question_tag1_count_dict[uid_tag1] += 1\n",
    "            u_prior4_question_timestamp_dict[user_id] = u_prior3_question_timestamp_dict[user_id]\n",
    "            u_prior3_question_timestamp_dict[user_id] = u_prior2_question_timestamp_dict[user_id]\n",
    "            u_prior2_question_timestamp_dict[user_id] = u_prior_question_timestamp_dict[user_id]\n",
    "            u_prior_question_timestamp_dict[user_id] = timestamp\n",
    "            u_task_container_id_dict[user_id] = task_container_id\n",
    "            u_prior_question_explanation_count_dict[user_id] += prior_question_had_explanation\n",
    "            if LorR == 0:\n",
    "                u_question_listening_count_dict[user_id] += 1\n",
    "            else:\n",
    "                u_question_reading_count_dict[user_id] += 1\n",
    "            u_question_seen_dict[user_id][content_id] = 1\n",
    "            \n",
    "            lru_cache.set(uid_cid, timestamp)\n",
    "            \n",
    "        else:\n",
    "            u_prior2_lecture_timestamp_dict[user_id] = u_prior_lecture_timestamp_dict[user_id]\n",
    "            u_prior_lecture_timestamp_dict[user_id] = timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:19.376030Z",
     "iopub.status.busy": "2021-01-07T12:59:19.375337Z",
     "iopub.status.idle": "2021-01-07T12:59:19.379294Z",
     "shell.execute_reply": "2021-01-07T12:59:19.378719Z"
    },
    "papermill": {
     "duration": 0.025939,
     "end_time": "2021-01-07T12:59:19.379417",
     "exception": false,
     "start_time": "2021-01-07T12:59:19.353478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'answered_correctly'\n",
    "FEATS = ['content_id', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'answered_correctly_avg_c', 'answered_correctly_var_c', 'part', 'question_asked', 'right_answers', 'bundle_size', 'bundle_rignt_answers', 'bundle_questions_asked', 'bundle_accuracy', 'part_rignt_answers', 'part_questions_asked', 'part_accuracy', 'tag1', 'tag1_answered_correctly_mean', 'tag1_answered_correctly_var', 'tags_emb_0', 'tags_emb_1', 'c_question_count_percent', 'c_question_part_percent', 'c_question_tag1_percent', 'c_question_unique_users_seen', 'u_answered_correctly_count', 'u_answered_count', 'u_question_part_correctly_count', 'u_question_part_count', 'u_question_tag1_correctly_count', 'u_question_tag1_count', 'u_prior_question_correctly_timestamp_diff', 'u_prior_question_correctly_timestamp_diff2', 'u_prior_question_correctly_timestamp_diff3', 'u_prior_question_timestamp_diff', 'u_prior_question_timestamp_diff2', 'u_prior_question_timestamp_diff3', 'u_prior_question_timestamp_diff4', 'u_prior_lecture_timestamp_diff', 'u_prior2_lecture_timestamp_diff', 'u_task_container_id_diff', 'u_prior_question_explanation_count', 'u_prior_question_explanation_correctly_count', 'u_question_listening_correctly_count', 'u_question_reading_correctly_count', 'u_question_listening_count', 'u_question_reading_count', 'u_question_incorrect_timestamp_diff', 'u_question_incorrect_timestamp_diff2', 'u_question_incorrect_timestamp_diff3', 'u_question_seen', 'u_question_nunique', 'u_question_part_correct_timestamp_diff', 'u_question_part_incorrect_timestamp_diff', 'uc_question_timestamp_diff', 'u_answered_correctly_avg', 'u_question_part_correctly_avg', 'u_question_tag1_correctly_avg', 'u_prior_question_timestamp_diff_2_1', 'u_prior_question_timestamp_diff_3_2', 'u_prior_question_timestamp_diff_4_3', 'u_question_timestamp_diff', 'u_question_timestamp_diff2', 'u_question_timestamp_diff3', 'u_listening_reading_ratio', 'u_listening_correctly_avg', 'u_reading_correctly_avg']\n",
    "\n",
    "prior_question_elapsed_time_mean = 25340.273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012784,
     "end_time": "2021-01-07T12:59:19.405443",
     "exception": false,
     "start_time": "2021-01-07T12:59:19.392659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SAKT 0.777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:19.436904Z",
     "iopub.status.busy": "2021-01-07T12:59:19.436230Z",
     "iopub.status.idle": "2021-01-07T12:59:19.439372Z",
     "shell.execute_reply": "2021-01-07T12:59:19.439851Z"
    },
    "papermill": {
     "duration": 0.021445,
     "end_time": "2021-01-07T12:59:19.439995",
     "exception": false,
     "start_time": "2021-01-07T12:59:19.418550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ = 240\n",
    "ACCEPTED_USER_CONTENT_SIZE = 2\n",
    "EMBED_SIZE = 256\n",
    "BATCH_SIZE = 96\n",
    "DROPOUT = 0.1\n",
    "\n",
    "n_skill = 13523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:19.510449Z",
     "iopub.status.busy": "2021-01-07T12:59:19.496164Z",
     "iopub.status.idle": "2021-01-07T12:59:19.513654Z",
     "shell.execute_reply": "2021-01-07T12:59:19.512956Z"
    },
    "papermill": {
     "duration": 0.060242,
     "end_time": "2021-01-07T12:59:19.513770",
     "exception": false,
     "start_time": "2021-01-07T12:59:19.453528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size = 200, forward_expansion = 1, bn_size = MAX_SEQ - 1, dropout=0.2):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        self.lr1 = nn.Linear(state_size, forward_expansion * state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(bn_size)\n",
    "        self.lr2 = nn.Linear(forward_expansion * state_size, state_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.lr1(x))\n",
    "        x = self.bn(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class FFN0(nn.Module):\n",
    "    def __init__(self, state_size = 200, forward_expansion = 1, bn_size = MAX_SEQ - 1, dropout=0.2):\n",
    "        super(FFN0, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear(state_size, forward_expansion * state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(forward_expansion * state_size, state_size)\n",
    "        self.layer_normal = nn.LayerNorm(state_size) \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        x=self.layer_normal(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "def future_mask(seq_length):\n",
    "    future_mask = (np.triu(np.ones([seq_length, seq_length]), k = 1)).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, heads = 8, dropout = DROPOUT, forward_expansion = 1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=heads, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = FFN(embed_dim, forward_expansion = forward_expansion, dropout=dropout)\n",
    "        self.ffn0  = FFN0(embed_dim, forward_expansion = forward_expansion, dropout=dropout)\n",
    "        self.layer_normal_2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, value, key, query, att_mask):\n",
    "        att_output, att_weight = self.multi_att(value, key, query, attn_mask=att_mask)\n",
    "        att_output = self.dropout(self.layer_normal(att_output + value))\n",
    "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "        x = self.ffn(att_output)\n",
    "        x1 = self.ffn0(att_output)\n",
    "        x = self.dropout(self.layer_normal_2(x + x1 + att_output))\n",
    "        return x.squeeze(-1), att_weight\n",
    "    \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=100, embed_dim=128, dropout = DROPOUT, forward_expansion = 1, num_layers=1, heads = 8):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_skill, self.embed_dim = n_skill, embed_dim\n",
    "        self.embedding = nn.Embedding(2 * n_skill + 1, embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_seq - 1, embed_dim)\n",
    "        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, forward_expansion = forward_expansion) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, question_ids):\n",
    "        device = x.device\n",
    "        x = self.embedding(x)\n",
    "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        x = self.dropout(x + pos_x)\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        e = self.e_embedding(question_ids)\n",
    "        e = e.permute(1, 0, 2)\n",
    "        for layer in self.layers:\n",
    "            att_mask = future_mask(e.size(0)).to(device)\n",
    "            x, att_weight = layer(e, x, x, att_mask=att_mask)\n",
    "            x = x.permute(1, 0, 2)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        return x, att_weight\n",
    "    \n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=100, embed_dim=128, dropout = DROPOUT, forward_expansion = 1, enc_layers=1, heads = 8):\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.encoder = Encoder(n_skill, max_seq, embed_dim, dropout, forward_expansion, num_layers=enc_layers)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "        \n",
    "    def forward(self, x, question_ids):\n",
    "        x, att_weight = self.encoder(x, question_ids)\n",
    "        x = self.pred(x)\n",
    "        return x.squeeze(-1), att_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:19.545763Z",
     "iopub.status.busy": "2021-01-07T12:59:19.545071Z",
     "iopub.status.idle": "2021-01-07T12:59:47.718110Z",
     "shell.execute_reply": "2021-01-07T12:59:47.717266Z"
    },
    "papermill": {
     "duration": 28.191224,
     "end_time": "2021-01-07T12:59:47.718236",
     "exception": false,
     "start_time": "2021-01-07T12:59:19.527012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "group = joblib.load(\"../input/v4-fork-of-riiid-sakt-model-full/group.pkl.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:47.798786Z",
     "iopub.status.busy": "2021-01-07T12:59:47.776498Z",
     "iopub.status.idle": "2021-01-07T12:59:48.789116Z",
     "shell.execute_reply": "2021-01-07T12:59:48.789904Z"
    },
    "papermill": {
     "duration": 1.057453,
     "end_time": "2021-01-07T12:59:48.790092",
     "exception": false,
     "start_time": "2021-01-07T12:59:47.732639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKTModel(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(27047, 256)\n",
       "    (pos_embedding): Embedding(239, 256)\n",
       "    (e_embedding): Embedding(13524, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (multi_att): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_normal): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (lr1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (bn): BatchNorm1d(239, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lr2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffn0): FFN0(\n",
       "          (lr1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (lr2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (layer_normal): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_normal_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (pred): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nn_model = SAKTModel(n_skill, \n",
    "                     max_seq=MAX_SEQ, \n",
    "                     embed_dim=EMBED_SIZE, \n",
    "                     forward_expansion=1, \n",
    "                     enc_layers=1, \n",
    "                     heads=4, \n",
    "                     dropout=0.1)\n",
    "\n",
    "try:\n",
    "    nn_model.load_state_dict(torch.load(\"../input/v4-fork-of-riiid-sakt-model-full/sakt_model.pt\"))\n",
    "except:\n",
    "    nn_model.load_state_dict(torch.load(\"../input/v4-fork-of-riiid-sakt-model-full/sakt_model.pt\", \n",
    "                                        map_location='cpu'))\n",
    "\n",
    "nn_model.to(device)\n",
    "nn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:48.847651Z",
     "iopub.status.busy": "2021-01-07T12:59:48.846566Z",
     "iopub.status.idle": "2021-01-07T12:59:48.849241Z",
     "shell.execute_reply": "2021-01-07T12:59:48.849837Z"
    },
    "papermill": {
     "duration": 0.040524,
     "end_time": "2021-01-07T12:59:48.849979",
     "exception": false,
     "start_time": "2021-01-07T12:59:48.809455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, n_skill, max_seq=100):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.samples, self.user_ids, self.test_df = samples, [x for x in test_df[\"user_id\"].unique()], test_df\n",
    "        self.n_skill, self.max_seq = n_skill, max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "        \n",
    "        user_id = test_info['user_id']\n",
    "        target_id = test_info['content_id']\n",
    "        \n",
    "        content_id_seq = np.zeros(self.max_seq, dtype=int)\n",
    "        answered_correctly_seq = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "        if user_id in self.samples.index:\n",
    "            content_id, answered_correctly = self.samples[user_id]\n",
    "            \n",
    "            seq_len = len(content_id)\n",
    "            \n",
    "            if seq_len >= self.max_seq:\n",
    "                content_id_seq = content_id[-self.max_seq:]\n",
    "                answered_correctly_seq = answered_correctly[-self.max_seq:]\n",
    "            else:\n",
    "                content_id_seq[-seq_len:] = content_id\n",
    "                answered_correctly_seq[-seq_len:] = answered_correctly\n",
    "                \n",
    "        x = content_id_seq[1:].copy()\n",
    "        x += (answered_correctly_seq[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append(content_id_seq[2:], [target_id])\n",
    "        \n",
    "        return x, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:48.884553Z",
     "iopub.status.busy": "2021-01-07T12:59:48.883792Z",
     "iopub.status.idle": "2021-01-07T12:59:48.910684Z",
     "shell.execute_reply": "2021-01-07T12:59:48.910015Z"
    },
    "papermill": {
     "duration": 0.04658,
     "end_time": "2021-01-07T12:59:48.910808",
     "exception": false,
     "start_time": "2021-01-07T12:59:48.864228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()\n",
    "set_predict = env.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:48.979454Z",
     "iopub.status.busy": "2021-01-07T12:59:48.953909Z",
     "iopub.status.idle": "2021-01-07T12:59:50.533494Z",
     "shell.execute_reply": "2021-01-07T12:59:50.532582Z"
    },
    "papermill": {
     "duration": 1.608374,
     "end_time": "2021-01-07T12:59:50.533624",
     "exception": false,
     "start_time": "2021-01-07T12:59:48.925250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cols = ['user_id', 'content_type_id', 'part', \n",
    "            'tag1', 'timestamp', 'task_container_id', \n",
    "            'prior_question_had_explanation', 'LorR', \n",
    "            'content_id']\n",
    "\n",
    "previous_test_df = None\n",
    "prev_test_df1 = None\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    \n",
    "    # SAKT inference\n",
    "    test_df1 = test_df.copy()\n",
    "    if prev_test_df1 is not None:\n",
    "        prev_test_df1['answered_correctly'] = eval(test_df1['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df1 = prev_test_df1[prev_test_df1.content_type_id == False]        \n",
    "        prev_group = prev_test_df1[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values))\n",
    "        \n",
    "        for prev_user_id in prev_group.index:\n",
    "            if prev_user_id in group.index:\n",
    "                group[prev_user_id] = (\n",
    "                    np.append(group[prev_user_id][0], prev_group[prev_user_id][0])[-MAX_SEQ:], \n",
    "                    np.append(group[prev_user_id][1], prev_group[prev_user_id][1])[-MAX_SEQ:]\n",
    "                )\n",
    " \n",
    "            else:\n",
    "                group[prev_user_id] = (\n",
    "                    prev_group[prev_user_id][0], \n",
    "                    prev_group[prev_user_id][1]\n",
    "                )\n",
    "                \n",
    "    prev_test_df1 = test_df1.copy()\n",
    "    test_df1 = test_df1[test_df1.content_type_id == False]\n",
    "    test_dataset = TestDataset(group, test_df1, n_skill, max_seq=MAX_SEQ)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
    "    \n",
    "    outs = []\n",
    "    for item in test_dataloader:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        with torch.no_grad():\n",
    "            output, _ = nn_model(x, target_id)\n",
    "        outs.extend(torch.sigmoid(output)[:, -1].view(-1).data.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LGBM inference\n",
    "    test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "    test_df = pd.merge(test_df, questions_df, on='content_id', how='left')\n",
    "    test_df = pd.merge(test_df, content_df, on='content_id', how='left')\n",
    "    test_df['prior_question_elapsed_time'] = test_df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "    test_df.fillna(-1, inplace=True)\n",
    "    test_df[use_cols] = test_df[use_cols].astype('int')\n",
    "    \n",
    "    if previous_test_df is not None:\n",
    "        previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "        previous_test_df[TARGET] = previous_test_df[TARGET].astype('int')\n",
    "        update_user_feats(previous_test_df, \n",
    "                          u_answered_correctly_count_dict,\n",
    "                          u_answered_count_dict, \n",
    "                          u_question_part_correctly_count_dict,\n",
    "                          u_question_part_count_dict,\n",
    "                          u_question_tag1_correctly_count_dict,\n",
    "                          u_question_tag1_count_dict,\n",
    "                          u_prior_question_correctly_timestamp_dict,\n",
    "                          u_prior2_question_correctly_timestamp_dict,\n",
    "                          u_prior3_question_correctly_timestamp_dict,\n",
    "                          u_prior_question_timestamp_dict,\n",
    "                          u_prior2_question_timestamp_dict,\n",
    "                          u_prior3_question_timestamp_dict,\n",
    "                          u_prior4_question_timestamp_dict,\n",
    "                          u_prior_lecture_timestamp_dict,\n",
    "                          u_prior2_lecture_timestamp_dict,\n",
    "                          u_task_container_id_dict,\n",
    "                          u_prior_question_explanation_count_dict,\n",
    "                          u_prior_question_explanation_correctly_count_dict,\n",
    "                          u_question_listening_correctly_count_dict, \n",
    "                          u_question_reading_correctly_count_dict,\n",
    "                          u_question_listening_count_dict, \n",
    "                          u_question_reading_count_dict,\n",
    "                          u_question_incorrect_timestamp_dict,\n",
    "                          u_question_incorrect_timestamp2_dict,\n",
    "                          u_question_incorrect_timestamp3_dict,\n",
    "                          u_question_seen_dict,\n",
    "                          u_question_part_correct_timestamp_dict, \n",
    "                          u_question_part_incorrect_timestamp_dict)\n",
    "        \n",
    "    previous_test_df = test_df.copy()\n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "    test_df = add_user_feats_without_update(test_df,\n",
    "                                            u_answered_correctly_count_dict,\n",
    "                                            u_answered_count_dict, \n",
    "                                            u_question_part_correctly_count_dict,\n",
    "                                            u_question_part_count_dict,\n",
    "                                            u_question_tag1_correctly_count_dict,\n",
    "                                            u_question_tag1_count_dict,\n",
    "                                            u_prior_question_correctly_timestamp_dict,\n",
    "                                            u_prior2_question_correctly_timestamp_dict,\n",
    "                                            u_prior3_question_correctly_timestamp_dict,\n",
    "                                            u_prior_question_timestamp_dict,\n",
    "                                            u_prior2_question_timestamp_dict,\n",
    "                                            u_prior3_question_timestamp_dict,\n",
    "                                            u_prior4_question_timestamp_dict,\n",
    "                                            u_prior_lecture_timestamp_dict,\n",
    "                                            u_prior2_lecture_timestamp_dict,\n",
    "                                            u_task_container_id_dict,\n",
    "                                            u_prior_question_explanation_count_dict,\n",
    "                                            u_prior_question_explanation_correctly_count_dict,\n",
    "                                            u_question_listening_correctly_count_dict, \n",
    "                                            u_question_reading_correctly_count_dict,\n",
    "                                            u_question_listening_count_dict, \n",
    "                                            u_question_reading_count_dict,\n",
    "                                            u_question_incorrect_timestamp_dict,\n",
    "                                            u_question_incorrect_timestamp2_dict,\n",
    "                                            u_question_incorrect_timestamp3_dict,\n",
    "                                            u_question_seen_dict,\n",
    "                                            u_question_part_correct_timestamp_dict, \n",
    "                                            u_question_part_incorrect_timestamp_dict)\n",
    "    \n",
    "    test_df[TARGET] = model.predict(test_df[FEATS])\n",
    "    \n",
    "    # blend\n",
    "    test_df[TARGET] = 0.75*test_df[TARGET] + 0.25*np.array(outs)\n",
    "    \n",
    "    \n",
    "    set_predict(test_df[['row_id', TARGET]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T12:59:50.569384Z",
     "iopub.status.busy": "2021-01-07T12:59:50.568629Z",
     "iopub.status.idle": "2021-01-07T12:59:51.538056Z",
     "shell.execute_reply": "2021-01-07T12:59:51.537441Z"
    },
    "papermill": {
     "duration": 0.990012,
     "end_time": "2021-01-07T12:59:51.538169",
     "exception": false,
     "start_time": "2021-01-07T12:59:50.548157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id,answered_correctly\r\n",
      "0,0.36327344343356793\r\n",
      "1,0.8857490012077305\r\n",
      "2,0.6622038262751303\r\n",
      "3,0.8570988935355467\r\n",
      "4,0.32162905766284416\r\n",
      "5,0.6885190924316829\r\n",
      "6,0.5101505815670148\r\n",
      "7,0.5999243195653847\r\n",
      "8,0.784834434358329\r\n",
      "9,0.5629938440087059\r\n",
      "10,0.8245712406821528\r\n",
      "11,0.5602268239093686\r\n",
      "12,0.4653338264689878\r\n",
      "13,0.7435863065782544\r\n",
      "14,0.31396741173064713\r\n",
      "15,0.7635788674639628\r\n",
      "16,0.5497390390475636\r\n",
      "17,0.9463706452982978\r\n",
      "18,0.7103668356173949\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014659,
     "end_time": "2021-01-07T12:59:51.568047",
     "exception": false,
     "start_time": "2021-01-07T12:59:51.553388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 133.293597,
   "end_time": "2021-01-07T12:59:52.735135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-07T12:57:39.441538",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
